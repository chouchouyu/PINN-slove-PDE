import numpy as np
import matplotlib
import matplotlib.pyplot as plt
from BlackScholesBarenblatt import BlackScholesBarenblatt
from DeepBSDE import BlackScholesBarenblattSolver, rel_error_l2
import time
import pandas as pd
from scipy import stats
from matplotlib.patches import Patch

# è§£å†³ä¸­æ–‡ä¹±ç é—®é¢˜
# åœ¨macOSä¸Šä½¿ç”¨ç³»ç»Ÿè‡ªå¸¦çš„ä¸­æ–‡å­—ä½“
matplotlib.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'Heiti TC', 'Microsoft YaHei']  # ä½¿ç”¨ç³»ç»Ÿæ”¯æŒçš„ä¸­æ–‡å­—ä½“
matplotlib.rcParams['axes.unicode_minus'] = False  # è§£å†³è´Ÿå·æ˜¾ç¤ºé—®é¢˜


# ä»test.pyä¸­å¯¼å…¥çš„å‡½æ•°
def test_standard_deepbsde(d=30, verbose=True):
    """æµ‹è¯•æ ‡å‡†DeepBSDEç®—æ³•
    
    å‚æ•°:
    d: é—®é¢˜ç»´åº¦ï¼Œé»˜è®¤ä¸º30
    verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯ï¼Œé»˜è®¤ä¸ºTrue
    
    è¿”å›:
    solver_std: æ ‡å‡†ç®—æ³•æ±‚è§£å™¨
    result_std: æ ‡å‡†ç®—æ³•æ±‚è§£ç»“æœ
    error_std: æ ‡å‡†ç®—æ³•è¯¯å·®
    """
    if verbose:
        print("=== 30ç»´Black-Scholes-Barenblattæ–¹ç¨‹æ±‚è§£ ===")
        print("\n1. æ ‡å‡†DeepBSDEç®—æ³•:")
    
    # æµ‹è¯•æ ‡å‡†ç‰ˆæœ¬ï¼ˆlimits=falseï¼‰
    solver_std = BlackScholesBarenblattSolver(d=d)
    result_std = solver_std.solve(limits=False, verbose=verbose)
    
    # éªŒè¯æ ‡å‡†ç‰ˆæœ¬ç»“æœ
    u_pred_std = result_std.us if hasattr(result_std.us, '__len__') else result_std.us
    u_anal_std = solver_std.analytical_solution(solver_std.x0, solver_std.tspan[0]).item()
    if hasattr(u_pred_std, '__len__'):
        error_std = rel_error_l2(u_pred_std[-1], u_anal_std)
    else:
        error_std = rel_error_l2(u_pred_std, u_anal_std)
    
    if verbose:
        print(f"æ ‡å‡†ç®—æ³•è¯¯å·®: {error_std:.6f}")
    
    return solver_std, result_std, error_std


def test_legendre_deepbsde(d=30, verbose=True):
    """æµ‹è¯•å¸¦Legendreå˜æ¢å¯¹å¶æ–¹æ³•çš„DeepBSDE
    
    å‚æ•°:
    d: é—®é¢˜ç»´åº¦ï¼Œé»˜è®¤ä¸º30
    verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯ï¼Œé»˜è®¤ä¸ºTrue
    
    è¿”å›:
    solver_limits: å¸¦Legendreå˜æ¢çš„æ±‚è§£å™¨
    result_limits: å¸¦Legendreå˜æ¢çš„æ±‚è§£ç»“æœ
    error_limits: å¸¦Legendreå˜æ¢çš„æ±‚è§£è¯¯å·®
    """
    if verbose:
        print("\n2. å¸¦Legendreå˜æ¢å¯¹å¶æ–¹æ³•çš„DeepBSDE:")
    
    # æµ‹è¯•å¸¦Legendreå˜æ¢çš„ç‰ˆæœ¬ï¼ˆlimits=trueï¼‰
    solver_limits = BlackScholesBarenblattSolver(d=d)
    result_limits = solver_limits.solve(
        limits=True, 
        trajectories_upper=1000,  # ä¸JuliaåŸæ–‡ä»¶ä¸€è‡´
        trajectories_lower=1000,  # ä¸JuliaåŸæ–‡ä»¶ä¸€è‡´
        maxiters_limits=10,       # ä¸JuliaåŸæ–‡ä»¶ä¸€è‡´
        verbose=verbose
    )
    
    # éªŒè¯å¸¦ç•Œé™ç‰ˆæœ¬ç»“æœ
    u_pred_limits = result_limits.us if hasattr(result_limits.us, '__len__') else result_limits.us
    u_anal_limits = solver_limits.analytical_solution(solver_limits.x0, solver_limits.tspan[0]).item()
    if hasattr(u_pred_limits, '__len__'):
        error_limits = rel_error_l2(u_pred_limits[-1], u_anal_limits)
    else:
        error_limits = rel_error_l2(u_pred_limits, u_anal_limits)
    
    if verbose:
        print(f"å¯¹å¶æ–¹æ³•è¯¯å·®: {error_limits:.6f}")
    
    return solver_limits, result_limits, error_limits


# ä»cqf_2_deepbsde_6yaobaoTrue2.pyä¸­å¯¼å…¥çš„è¾…åŠ©å‡½æ•°
def calculate_proper_error_bars(intervals, point_estimates):
    """è®¡ç®—åˆé€‚çš„è¯¯å·®æ¡ - ä¿®å¤ç‰ˆæœ¬"""
    errors_lower = []
    errors_upper = []
    violations = 0
    
    for (low, high), u0 in zip(intervals, point_estimates):
        if u0 < low:
            # ç‚¹ä¼°è®¡ä½äºä¸‹ç•Œï¼Œè°ƒæ•´æ˜¾ç¤º
            errors_lower.append(low - u0)
            errors_upper.append(high - u0)
            violations += 1
        elif u0 > high:
            # ç‚¹ä¼°è®¡é«˜äºä¸Šç•Œ
            errors_lower.append(u0 - low)
            errors_upper.append(u0 - high)
            violations += 1
        else:
            # æ­£å¸¸æƒ…å†µ
            errors_lower.append(u0 - low)
            errors_upper.append(high - u0)
    
    if violations > 0:
        print(f"è­¦å‘Š: {violations}ä¸ªç‚¹ä¼°è®¡è¶…å‡ºç½®ä¿¡åŒºé—´")
    
    return errors_lower, errors_upper, violations


def plot_improved_confidence_intervals(metrics, analytical_value, ax):
    """æ”¹è¿›çš„ç½®ä¿¡åŒºé—´å¯è§†åŒ– - ä¿®å¤ç‰ˆæœ¬"""
    if not metrics.get('limits_intervals'):
        ax.text(0.5, 0.5, 'æ— ç½®ä¿¡åŒºé—´æ•°æ®', 
                transform=ax.transAxes, ha='center', va='center')
        ax.set_title('ç½®ä¿¡åŒºé—´å¯è§†åŒ–')
        return ax
    
    # è®¡ç®—è¯¯å·®æ¡
    errors_lower, errors_upper, violations = calculate_proper_error_bars(
        metrics['limits_intervals'], metrics['limits_u0']
    )
    
    # ç¡®ä¿è¯¯å·®æ¡éè´Ÿ
    errors_lower = np.abs(errors_lower)
    errors_upper = np.abs(errors_upper)
    
    # ç»˜åˆ¶è¯¯å·®æ¡
    x_positions = range(len(metrics['limits_intervals']))
    
    # ä½¿ç”¨ä¸åŒçš„é¢œè‰²æ ‡è®°è¿è§„ç‚¹
    colors = ['red' if (u0 < low or u0 > high) else 'blue' 
             for (low, high), u0 in zip(metrics['limits_intervals'], metrics['limits_u0'])]
    
    # åˆ†åˆ«ç»˜åˆ¶æ­£å¸¸ç‚¹å’Œè¿è§„ç‚¹
    normal_x = []
    normal_y = []
    normal_lower = []
    normal_upper = []
    
    violation_x = []
    violation_y = []
    violation_lower = []
    violation_upper = []
    
    for i, ((low, high), u0, color) in enumerate(zip(metrics['limits_intervals'], metrics['limits_u0'], colors)):
        if color == 'blue':
            normal_x.append(i)
            normal_y.append(u0)
            normal_lower.append(errors_lower[i])
            normal_upper.append(errors_upper[i])
        else:
            violation_x.append(i)
            violation_y.append(u0)
            violation_lower.append(errors_lower[i])
            violation_upper.append(errors_upper[i])
    
    # ç»˜åˆ¶æ­£å¸¸ç‚¹
    if normal_x:
        ax.errorbar(
            normal_x, normal_y, 
            yerr=[normal_lower, normal_upper],
            fmt='o', capsize=5, color='blue', alpha=0.7,
            label='æ­£å¸¸ç‚¹'
        )
    
    # ç»˜åˆ¶è¿è§„ç‚¹
    if violation_x:
        ax.errorbar(
            violation_x, violation_y, 
            yerr=[violation_lower, violation_upper],
            fmt='o', capsize=5, color='red', alpha=0.7,
            label='è¿è§„ç‚¹'
        )
    
    # æ·»åŠ è§£æè§£å‚è€ƒçº¿
    ax.axhline(y=analytical_value, color='green', linestyle='--', 
              label=f'è§£æè§£: {analytical_value:.2f}')
    
    # æ·»åŠ ç½®ä¿¡åŒºé—´èƒŒæ™¯
    for i, (low, high) in enumerate(metrics['limits_intervals']):
        ax.axhspan(low, high, alpha=0.1, color='gray')
    
    ax.set_xlabel('è¯•éªŒæ¬¡æ•°')
    ax.set_ylabel('u0ä¼°è®¡å€¼')
    ax.set_title('ç½®ä¿¡åŒºé—´å¯è§†åŒ–ï¼ˆæ”¹è¿›ç‰ˆï¼‰')
    
    # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
    coverage = sum(1 for (low, high), u0 in zip(metrics['limits_intervals'], metrics['limits_u0'])
                   if low <= u0 <= high) / len(metrics['limits_intervals']) * 100
    
    stats_text = f'è¦†ç›–ç‡: {coverage:.1f}%\nè¿è§„ç‚¹: {violations}ä¸ª'
    ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, 
            verticalalignment='top',
            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))
    
    # æ·»åŠ å›¾ä¾‹
    legend_elements = [
        Patch(facecolor='blue', alpha=0.7, label='æ­£å¸¸ç‚¹'),
        Patch(facecolor='red', alpha=0.7, label='è¿è§„ç‚¹'),
        Patch(facecolor='gray', alpha=0.1, label='ç½®ä¿¡åŒºé—´')
    ]
    ax.legend(handles=legend_elements)
    
    ax.grid(True, alpha=0.3)
    return ax


def plot_comprehensive_comparison(metrics, results_std, results_limits, d):
    """ç»˜åˆ¶ç»¼åˆå¯¹æ¯”å›¾è¡¨ - é›†æˆæ–¹æ¡ˆ3æ”¹è¿›"""
    fig, axes = plt.subplots(2, 3, figsize=(18, 12))
    
    # 1. è¯¯å·®åˆ†å¸ƒå¯¹æ¯”
    axes[0,0].boxplot([metrics['std_errors'], metrics['limits_errors']], 
                      labels=['æ ‡å‡†æ–¹æ³•', 'å¯¹å¶æ–¹æ³•'])
    axes[0,0].set_ylabel('ç›¸å¯¹è¯¯å·®')
    axes[0,0].set_title('è¯¯å·®åˆ†å¸ƒå¯¹æ¯”')
    axes[0,0].grid(True, alpha=0.3)
    
    # 2. è®­ç»ƒæ—¶é—´å¯¹æ¯”
    axes[0,1].boxplot([metrics['std_times'], metrics['limits_times']], 
                     labels=['æ ‡å‡†æ–¹æ³•', 'å¯¹å¶æ–¹æ³•'])
    axes[0,1].set_ylabel('è®­ç»ƒæ—¶é—´ (ç§’)')
    axes[0,1].set_title('è®¡ç®—æ•ˆç‡å¯¹æ¯”')
    axes[0,1].grid(True, alpha=0.3)
    
    # 3. è§£å€¼ç¨³å®šæ€§
    axes[0,2].plot(metrics['std_u0'], 'bo-', label='æ ‡å‡†æ–¹æ³•', alpha=0.7)
    axes[0,2].plot(metrics['limits_u0'], 'ro-', label='å¯¹å¶æ–¹æ³•', alpha=0.7)
    analytical_value = results_std[0][0].analytical_solution(
        results_std[0][0].x0, results_std[0][0].tspan[0]).item()
    axes[0,2].axhline(y=analytical_value, color='green', linestyle='--', 
                     label=f'è§£æè§£: {analytical_value:.2f}')
    axes[0,2].set_xlabel('è¯•éªŒæ¬¡æ•°')
    axes[0,2].set_ylabel('u0ä¼°è®¡å€¼')
    axes[0,2].set_title('è§£å€¼ç¨³å®šæ€§å¯¹æ¯”')
    axes[0,2].legend()
    axes[0,2].grid(True, alpha=0.3)
    
    # 4. è®­ç»ƒæŸå¤±æ›²çº¿å¯¹æ¯”ï¼ˆæœ€åä¸€æ¬¡è¯•éªŒï¼‰
    if results_std and hasattr(results_std[-1][0], 'losses'):
        axes[1,0].semilogy(results_std[-1][0].losses, label='æ ‡å‡†æ–¹æ³•')
    if results_limits and hasattr(results_limits[-1][0], 'losses'):
        axes[1,0].semilogy(results_limits[-1][0].losses, label='å¯¹å¶æ–¹æ³•')
    axes[1,0].set_xlabel('è¿­ä»£æ¬¡æ•°')
    axes[1,0].set_ylabel('æŸå¤±å€¼')
    axes[1,0].set_title('è®­ç»ƒè¿‡ç¨‹å¯¹æ¯”')
    axes[1,0].legend()
    axes[1,0].grid(True, alpha=0.3)
    
    # 5. ç½®ä¿¡åŒºé—´å¯è§†åŒ– - ä½¿ç”¨æ–¹æ¡ˆ3æ”¹è¿›æ–¹æ³•
    if metrics.get('limits_intervals'):
        plot_improved_confidence_intervals(metrics, analytical_value, axes[1,1])
    else:
        axes[1,1].text(0.5, 0.5, 'æ— ç½®ä¿¡åŒºé—´æ•°æ®', 
                      transform=axes[1,1].transAxes, ha='center', va='center')
        axes[1,1].set_title('ç½®ä¿¡åŒºé—´å¯è§†åŒ–')
    
    # 6. æ–¹æ³•ç‰¹æ€§é›·è¾¾å›¾ - ä¿®å¤ï¼šä½¿ç”¨æ­£ç¡®çš„æåæ ‡è®¾ç½®
    # é¦–å…ˆåˆ›å»ºä¸€ä¸ªæåæ ‡è½´
    fig.delaxes(axes[1,2])  # åˆ é™¤åŸæ¥çš„è½´
    ax_radar = fig.add_subplot(2, 3, 6, projection='polar')  # åˆ›å»ºæåæ ‡è½´
    
    characteristics = ['å‡†ç¡®æ€§', 'æ•ˆç‡', 'ç¨³å®šæ€§', 'ç†è®ºä¿è¯', 'æ˜“ç”¨æ€§', 'é€‚ç”¨æ€§']
    std_scores = [8, 9, 7, 7, 8, 9]
    limits_scores = [7, 6, 8, 9, 6, 8]
    
    angles = np.linspace(0, 2*np.pi, len(characteristics), endpoint=False).tolist()
    angles += angles[:1]
    std_scores += std_scores[:1]
    limits_scores += limits_scores[:1]
    characteristics += characteristics[:1]
    
    ax_radar.plot(angles, std_scores, 'o-', linewidth=2, label='æ ‡å‡†æ–¹æ³•')
    ax_radar.fill(angles, std_scores, alpha=0.25)
    ax_radar.plot(angles, limits_scores, 'o-', linewidth=2, label='å¯¹å¶æ–¹æ³•')
    ax_radar.fill(angles, limits_scores, alpha=0.25)
    ax_radar.set_xticks(angles[:-1])
    ax_radar.set_xticklabels(characteristics[:-1])
    ax_radar.set_title('æ–¹æ³•ç‰¹æ€§é›·è¾¾å›¾')
    ax_radar.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))
    
    plt.tight_layout()
    plt.suptitle(f'{d}ç»´Black-Scholes-Barenblattæ–¹ç¨‹æ±‚è§£æ–¹æ³•å¯¹æ¯”', fontsize=16, y=1.02)
    plt.show()


def comprehensive_comparison(d=30, num_trials=3):
    """å…¨é¢çš„æ–¹æ³•å¯¹æ¯”åˆ†æ - é›†æˆæ–¹æ¡ˆ3æ”¹è¿›"""
    print("=== DeepBSDEæ–¹æ³•å…¨é¢å¯¹æ¯”åˆ†æ ===")
    print(f"ç»´åº¦: {d}ç»´, è¯•éªŒæ¬¡æ•°: {num_trials}")
    print("=" * 60)
    
    results_std = []
    results_limits = []
    
    performance_metrics = {
        'std_errors': [], 'std_times': [], 'std_u0': [],
        'limits_errors': [], 'limits_times': [], 'limits_u0': [],
        'limits_lower': [], 'limits_upper': [], 'limits_intervals': []
    }
    
    for trial in range(num_trials):
        print(f"\n--- è¯•éªŒ {trial + 1}/{num_trials} ---")
        
        # æµ‹è¯•æ ‡å‡†æ–¹æ³•
        start_time = time.time()
        solver_std = BlackScholesBarenblattSolver(d=d)
        result_std = solver_std.solve(limits=False, verbose=False)
        std_time = time.time() - start_time
        
        u_pred_std = result_std.us if hasattr(result_std.us, '__len__') else result_std.us
        u_anal_std = solver_std.analytical_solution(solver_std.x0, solver_std.tspan[0]).item()
        error_std = rel_error_l2(u_pred_std, u_anal_std)
        
        # æµ‹è¯•å¸¦Legendreå˜æ¢æ–¹æ³•
        start_time = time.time()
        solver_limits = BlackScholesBarenblattSolver(d=d)
        result_limits = solver_limits.solve(
            limits=True, 
            trajectories_upper=200,
            trajectories_lower=200,
            maxiters_limits=5,
            verbose=False
        )
        limits_time = time.time() - start_time
        
        u_pred_limits = result_limits.us if hasattr(result_limits.us, '__len__') else result_limits.us
        u_anal_limits = solver_limits.analytical_solution(solver_limits.x0, solver_limits.tspan[0]).item()
        error_limits = rel_error_l2(u_pred_limits, u_anal_limits)
        
        # å­˜å‚¨ç»“æœ
        results_std.append((solver_std, result_std, error_std, std_time))
        results_limits.append((solver_limits, result_limits, error_limits, limits_time))
        
        # å­˜å‚¨æ€§èƒ½æŒ‡æ ‡
        performance_metrics['std_errors'].append(error_std)
        performance_metrics['std_times'].append(std_time)
        performance_metrics['std_u0'].append(u_pred_std)
        
        performance_metrics['limits_errors'].append(error_limits)
        performance_metrics['limits_times'].append(limits_time)
        performance_metrics['limits_u0'].append(u_pred_limits)
        
        if hasattr(result_limits, 'limits') and result_limits.limits is not None:
            u_low, u_high = result_limits.limits
            performance_metrics['limits_lower'].append(u_low)
            performance_metrics['limits_upper'].append(u_high)
            performance_metrics['limits_intervals'].append((u_low, u_high))
        
        print(f"æ ‡å‡†æ–¹æ³• - è¯¯å·®: {error_std:.6f}, æ—¶é—´: {std_time:.2f}s")
        print(f"å¯¹å¶æ–¹æ³• - è¯¯å·®: {error_limits:.6f}, æ—¶é—´: {limits_time:.2f}s")
        if hasattr(result_limits, 'limits') and result_limits.limits is not None:
            print(f"ç½®ä¿¡åŒºé—´: [{u_low:.4f}, {u_high:.4f}]")
    
    # æ€§èƒ½ç»Ÿè®¡åˆ†æ
    print("\n" + "="*60)
    print("                æ€§èƒ½å¯¹æ¯”åˆ†æç»“æœ")
    print("="*60)
    
    # åˆ›å»ºå¯¹æ¯”è¡¨æ ¼
    comparison_data = []
    
    # å‡†ç¡®æ€§å¯¹æ¯”
    std_error_mean = np.mean(performance_metrics['std_errors'])
    std_error_std = np.std(performance_metrics['std_errors'])
    limits_error_mean = np.mean(performance_metrics['limits_errors'])
    limits_error_std = np.std(performance_metrics['limits_errors'])
    
    # è®¡ç®—æ—¶é—´å¯¹æ¯”
    std_time_mean = np.mean(performance_metrics['std_times'])
    std_time_std = np.std(performance_metrics['std_times'])
    limits_time_mean = np.mean(performance_metrics['limits_times'])
    limits_time_std = np.std(performance_metrics['limits_times'])
    
    # è§£å€¼ç¨³å®šæ€§å¯¹æ¯”
    std_u0_std = np.std(performance_metrics['std_u0'])
    limits_u0_std = np.std(performance_metrics['limits_u0'])
    
    # ç½®ä¿¡åŒºé—´åˆ†æ
    coverage = 0
    if performance_metrics['limits_intervals']:
        analytical_value = results_limits[0][0].analytical_solution(
            results_limits[0][0].x0, results_limits[0][0].tspan[0]).item()
        for interval in performance_metrics['limits_intervals']:
            if interval[0] <= analytical_value <= interval[1]:
                coverage += 1
        coverage_rate = coverage / len(performance_metrics['limits_intervals'])
        interval_widths = [interval[1] - interval[0] for interval in performance_metrics['limits_intervals']]
        avg_interval_width = np.mean(interval_widths) if interval_widths else 0
    else:
        coverage_rate = 0
        avg_interval_width = 0
    
    # ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒ
    if len(performance_metrics['std_errors']) > 1 and len(performance_metrics['limits_errors']) > 1:
        t_stat, p_value = stats.ttest_ind(performance_metrics['std_errors'], 
                                         performance_metrics['limits_errors'])
    else:
        t_stat, p_value = 0, 1.0
    
    # è¾“å‡ºè¯¦ç»†å¯¹æ¯”è¡¨æ ¼
    print(f"\n{'æŒ‡æ ‡':<25} {'æ ‡å‡†æ–¹æ³•':<15} {'å¯¹å¶æ–¹æ³•':<15} {'ä¼˜åŠ£åˆ†æ':<20}")
    print("-" * 80)
    
    comparison_data.append([
        "å¹³å‡ç›¸å¯¹è¯¯å·®", 
        f"{std_error_mean:.6f} Â± {std_error_std:.6f}", 
        f"{limits_error_mean:.6f} Â± {limits_error_std:.6f}",
        "âœ“ æ ‡å‡†æ–¹æ³•æ›´ä¼˜" if std_error_mean < limits_error_mean else "âœ“ å¯¹å¶æ–¹æ³•æ›´ä¼˜"
    ])
    
    comparison_data.append([
        "å¹³å‡è®­ç»ƒæ—¶é—´(s)", 
        f"{std_time_mean:.2f} Â± {std_time_std:.2f}", 
        f"{limits_time_mean:.2f} Â± {limits_time_std:.2f}",
        "âœ“ æ ‡å‡†æ–¹æ³•æ›´å¿«" if std_time_mean < limits_time_mean else "âœ“ å¯¹å¶æ–¹æ³•æ›´å¿«"
    ])
    
    comparison_data.append([
        "è§£å€¼ç¨³å®šæ€§(æ ‡å‡†å·®)", 
        f"{std_u0_std:.6f}", 
        f"{limits_u0_std:.6f}",
        "âœ“ æ ‡å‡†æ–¹æ³•æ›´ç¨³å®š" if std_u0_std < limits_u0_std else "âœ“ å¯¹å¶æ–¹æ³•æ›´ç¨³å®š"
    ])
    
    if performance_metrics['limits_intervals']:
        comparison_data.append([
            "ç½®ä¿¡åŒºé—´è¦†ç›–ç‡", 
            "N/A", 
            f"{coverage_rate*100:.1f}%",
            "âœ“ è‰¯å¥½" if coverage_rate >= 0.9 else "â—‹ ä¸€èˆ¬" if coverage_rate >= 0.7 else "âœ— è¾ƒå·®"
        ])
        
        comparison_data.append([
            "å¹³å‡åŒºé—´å®½åº¦", 
            "N/A", 
            f"{avg_interval_width:.4f}",
            "âœ“ è¾ƒçª„" if avg_interval_width < 1.0 else "â—‹ é€‚ä¸­" if avg_interval_width < 3.0 else "âœ— è¾ƒå®½"
        ])
    
    comparison_data.append([
        "ç»Ÿè®¡æ˜¾è‘—æ€§(på€¼)", 
        "N/A", 
        f"{p_value:.6f}",
        "âœ“ æ˜¾è‘—å·®å¼‚" if p_value < 0.05 else "â—‹ æ— æ˜¾è‘—å·®å¼‚"
    ])
    
    for row in comparison_data:
        print(f"{row[0]:<25} {row[1]:<15} {row[2]:<15} {row[3]:<20}")
    
    # ç»˜åˆ¶ç»¼åˆå¯¹æ¯”å›¾è¡¨ï¼ˆåŒ…å«æ–¹æ¡ˆ3æ”¹è¿›çš„ç½®ä¿¡åŒºé—´å¯è§†åŒ–ï¼‰
    plot_comprehensive_comparison(performance_metrics, results_std, results_limits, d)
    
    # æ–¹æ³•ç‰¹æ€§è¯„åˆ†
    print("\n" + "="*60)
    print("                æ–¹æ³•ç‰¹æ€§ç»¼åˆè¯„åˆ†")
    print("="*60)
    
    characteristics = {
        'å‡†ç¡®æ€§': [max(0, 10 - std_error_mean*100), max(0, 10 - limits_error_mean*100)],
        'è®¡ç®—æ•ˆç‡': [max(0, 10 - std_time_mean/10), max(0, 10 - limits_time_mean/10)],
        'æ•°å€¼ç¨³å®šæ€§': [max(0, 10 - std_u0_std*10), max(0, 10 - limits_u0_std*10)],
        'ç†è®ºä¿è¯': [7, 9],
        'å®ç°å¤æ‚åº¦': [8, 6],
        'é€‚ç”¨æ€§': [9, 8]
    }
    
    if performance_metrics['limits_intervals']:
        characteristics['ä¸ç¡®å®šæ€§é‡åŒ–'] = [5, 8]
    
    methods = ['æ ‡å‡†æ–¹æ³•', 'å¯¹å¶æ–¹æ³•']
    print(f"{'ç‰¹æ€§':<15} {'æ ‡å‡†æ–¹æ³•':<10} {'å¯¹å¶æ–¹æ³•':<10} {'æ¨è':<10}")
    print("-" * 50)
    
    for char, scores in characteristics.items():
        std_score, limits_score = scores
        recommendation = "æ ‡å‡†æ–¹æ³•" if std_score > limits_score else "å¯¹å¶æ–¹æ³•" if limits_score > std_score else "ç›¸å½“"
        print(f"{char:<15} {std_score:<10.1f} {limits_score:<10.1f} {recommendation:<10}")
    
    # æ€»ä½“æ¨è
    total_std = sum([score[0] for score in characteristics.values()])
    total_limits = sum([score[1] for score in characteristics.values()])
    
    print("-" * 50)
    print(f"{'æ€»åˆ†':<15} {total_std:<10.1f} {total_limits:<10.1f} ", end="")
    if total_std > total_limits:
        print("âœ“ æ¨èæ ‡å‡†æ–¹æ³•")
    elif total_limits > total_std:
        print("âœ“ æ¨èå¯¹å¶æ–¹æ³•")
    else:
        print("â—‹ ä¸¤ç§æ–¹æ³•ç›¸å½“")
    
    return results_std, results_limits, performance_metrics


def main():
    """æ›´æ–°åçš„ä¸»å‡½æ•° - è°ƒç”¨å…¨é¢å¯¹æ¯”åˆ†æ"""
    print("=== DeepBSDEæ–¹æ³•å¯¹æ¯”åˆ†æ ===")
    
    # è¿è¡Œå…¨é¢å¯¹æ¯”åˆ†æ
    results_std, results_limits, metrics = comprehensive_comparison(d=30, num_trials=3)
    
    # è¾“å‡ºæœ€ç»ˆå»ºè®®
    print("\n" + "="*60)
    print("                æœ€ç»ˆä½¿ç”¨å»ºè®®")
    print("="*60)
    
    print("\nğŸ“Š åŸºäºå¯¹æ¯”åˆ†æï¼Œå»ºè®®å¦‚ä¸‹ï¼š")
    print("\nâœ… æ¨èä½¿ç”¨æ ‡å‡†DeepBSDEæ–¹æ³•çš„æƒ…å†µï¼š")
    print("   â€¢ éœ€è¦å¿«é€Ÿå¾—åˆ°ç‚¹ä¼°è®¡")
    print("   â€¢ è®¡ç®—èµ„æºæœ‰é™")
    print("   â€¢ é—®é¢˜ç›¸å¯¹ç®€å•ï¼Œä¸éœ€è¦ä¸ç¡®å®šæ€§é‡åŒ–")
    print("   â€¢ å®ç°å¤æ‚åº¦è¦æ±‚ä½")
    
    print("\nâœ… æ¨èä½¿ç”¨å¸¦Legendreå˜æ¢å¯¹å¶æ–¹æ³•çš„æƒ…å†µï¼š")
    print("   â€¢ éœ€è¦ç½®ä¿¡åŒºé—´ä¼°è®¡")
    print("   â€¢ å¯¹è§£çš„å¯é æ€§è¦æ±‚é«˜")
    print("   â€¢ æœ‰å……è¶³çš„è®¡ç®—èµ„æº")
    print("   â€¢ éœ€è¦è¿›è¡Œä¸¥æ ¼çš„ç†è®ºåˆ†æ")
    
    print("\nğŸ” å…³é”®å‘ç°ï¼š")
    if metrics['std_errors'] and metrics['limits_errors']:
        if np.mean(metrics['std_errors']) < np.mean(metrics['limits_errors']):
            print("   â€¢ æ ‡å‡†æ–¹æ³•åœ¨å‡†ç¡®æ€§ä¸Šç•¥ä¼˜")
        else:
            print("   â€¢ å¯¹å¶æ–¹æ³•åœ¨å‡†ç¡®æ€§ä¸Šç•¥ä¼˜")
        
        if np.mean(metrics['std_times']) < np.mean(metrics['limits_times']):
            print("   â€¢ æ ‡å‡†æ–¹æ³•åœ¨è®¡ç®—æ•ˆç‡ä¸Šæ˜æ˜¾æ›´ä¼˜")
        else:
            print("   â€¢ å¯¹å¶æ–¹æ³•åœ¨è®¡ç®—æ•ˆç‡ä¸Šæ›´ä¼˜")
    
    if metrics.get('limits_intervals'):
        analytical_value = results_limits[0][0].analytical_solution(
            results_limits[0][0].x0, results_limits[0][0].tspan[0]).item()
        coverage = sum(1 for interval in metrics['limits_intervals'] 
                      if interval[0] <= analytical_value <= interval[1])
        print(f"   â€¢ å¯¹å¶æ–¹æ³•æä¾›ç½®ä¿¡åŒºé—´ï¼Œè¦†ç›–ç‡ä¸º{coverage/len(metrics['limits_intervals'])*100:.1f}%")
    
    return results_std, results_limits, metrics


if __name__ == "__main__":
    results_std, results_limits, metrics = main()
