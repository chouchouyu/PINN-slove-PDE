"""
Black-Scholes-Barenblatt 30ç»´é—®é¢˜å¯¹æ¯”åˆ†æ
FBSNNsæ–¹æ³•ä¸DeepBSDEæ–¹æ³•å¯¹æ¯” - å®Œå…¨ä¿®å¤ç‰ˆ
ä¿®å¤äº†ç²¾ç¡®è§£è®¡ç®—çš„æµ®ç‚¹ç²¾åº¦é—®é¢˜å’Œå¼ é‡ç»´åº¦ä¸åŒ¹é…é—®é¢˜
"""

import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
import time
import json
from typing import Callable, Tuple, List, Dict, Any
import warnings
warnings.filterwarnings('ignore')

# ============== é€šç”¨å·¥å…·å‡½æ•° ==============
def set_seed(seed: int = 42):
    """è®¾ç½®éšæœºç§å­"""
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    np.random.seed(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

# ============== DeepBSDEæ–¹æ³•å®ç° (cqf_2_deepbsde_blackscholesbarenblatt) ==============
class DeepBSDENSolver:
    """DeepBSDEæ±‚è§£å™¨ - åŸºäºcqf_2_deepbsde_blackscholesbarenblatt"""
    
    def __init__(self, d=30, T=1.0, dt=0.05, hidden_size=20, 
                 learning_rate=0.001, device='cpu'):
        self.d = d
        self.T = T
        self.dt = dt
        self.n_time_steps = int(T / dt)
        self.hidden_size = hidden_size
        self.device = torch.device(device)
        
        # U0ç½‘ç»œ (è¿‘ä¼¼åˆå§‹å€¼)
        self.u0_net = nn.Sequential(
            nn.Linear(d, hidden_size),
            nn.Tanh(),
            nn.Linear(hidden_size, hidden_size),
            nn.Tanh(),
            nn.Linear(hidden_size, 1)
        ).to(self.device)
        
        # SigmaTGradUç½‘ç»œ (æ¯ä¸ªæ—¶é—´æ­¥ä¸€ä¸ªç½‘ç»œ)
        self.sigma_nets = nn.ModuleList([
            nn.Sequential(
                nn.Linear(d, hidden_size),
                nn.Tanh(),
                nn.Linear(hidden_size, hidden_size),
                nn.Tanh(),
                nn.Linear(hidden_size, d)
            ).to(self.device) for _ in range(self.n_time_steps)
        ])
        
        # ä¼˜åŒ–å™¨
        self.optimizer = optim.Adam(
            list(self.u0_net.parameters()) + list(self.sigma_nets.parameters()),
            lr=learning_rate
        )
        
        # æ—¶é—´ç½‘æ ¼
        self.ts = torch.linspace(0, T, self.n_time_steps + 1, device=self.device)
        
    def simulate_trajectories(self, X0, mu_func, sigma_func, f_func, trajectories=100):
        """æ¨¡æ‹Ÿè½¨è¿¹ - åŸºäºæ¬§æ‹‰-ä¸¸å±±æ–¹æ³•"""
        batch_size = trajectories
        d = self.d
        
        # åˆå§‹åŒ–
        X = X0.repeat(batch_size, 1).to(self.device)
        u = self.u0_net(X)
        
        X_trajectories = [X.clone()]
        u_trajectories = [u.clone()]
        
        for i in range(self.n_time_steps):
            t = self.ts[i]
            
            # è®¡ç®—sigmaè½¬ç½®æ¢¯åº¦
            sigma_T_grad_u = self.sigma_nets[i](X)
            
            # å¸ƒæœ—è¿åŠ¨å¢é‡
            dW = torch.sqrt(torch.tensor(self.dt, device=self.device)) * torch.randn_like(X)
            
            # æ›´æ–°u (BSDEç¦»æ•£)
            f_value = f_func(t, X, u, sigma_T_grad_u)
            u = u - f_value * self.dt + torch.sum(sigma_T_grad_u * dW, dim=1, keepdim=True)
            
            # æ›´æ–°X (SDEç¦»æ•£)
            mu_value = mu_func(t, X)
            sigma_value = sigma_func(t, X)
            
            # ä¿®å¤ï¼šå°†sigma_valueä»(batch_size, d, 1)è°ƒæ•´ä¸º(batch_size, d)
            if sigma_value.dim() == 3 and sigma_value.shape[2] == 1:
                sigma_value = sigma_value.squeeze(-1)  # ä»(batch_size, d, 1)å˜ä¸º(batch_size, d)
            elif sigma_value.dim() == 2 and sigma_value.shape[1] == 1:
                sigma_value = sigma_value.squeeze(1)  # ä»(batch_size, 1)å˜ä¸º(batch_size,)
            
            X = X + mu_value * self.dt + sigma_value * dW
            
            X_trajectories.append(X.clone())
            u_trajectories.append(u.clone())
        
        return X_trajectories, u_trajectories
    
    def train(self, X0, mu_func, sigma_func, f_func, g_func, 
              n_iterations=150, batch_size=64, verbose=True):
        """è®­ç»ƒDeepBSDEæ±‚è§£å™¨"""
        losses = []
        
        for iteration in range(n_iterations):
            # æ¨¡æ‹Ÿè½¨è¿¹
            trajectories_result = self.simulate_trajectories(
                X0, mu_func, sigma_func, f_func, trajectories=batch_size
            )
            X_final = trajectories_result[0][-1]
            u_final = trajectories_result[1][-1]
            
            # è®¡ç®—ç»ˆç«¯æ¡ä»¶çš„æŸå¤±
            g_value = g_func(X_final)
            loss = torch.mean((g_value - u_final) ** 2)
            
            # åå‘ä¼ æ’­
            self.optimizer.zero_grad()
            loss.backward()
            torch.nn.utils.clip_grad_norm_(
                list(self.u0_net.parameters()) + list(self.sigma_nets.parameters()),
                max_norm=1.0
            )
            self.optimizer.step()
            
            losses.append(loss.item())
            
            if verbose and (iteration + 1) % 10 == 0:
                print(f'DeepBSDE - è¿­ä»£ {iteration + 1}/{n_iterations}, æŸå¤±: {loss.item():.6f}')
        
        return losses
    
    def predict(self, X):
        """é¢„æµ‹åˆå§‹å€¼"""
        with torch.no_grad():
            X_tensor = torch.as_tensor(X, device=self.device, dtype=torch.float32)
            if len(X_tensor.shape) == 1:
                X_tensor = X_tensor.unsqueeze(0)
            return self.u0_net(X_tensor).cpu().numpy()

# ============== FBSNNsæ–¹æ³•å®ç° ==============
class FBSNNsSolver:
    """FBSNNsæ±‚è§£å™¨ - åŸºäºFBSNNsæ¡†æ¶"""
    
    def __init__(self, d=30, T=1.0, dt=0.05, hidden_size=20, 
                 learning_rate=0.001, device='cpu'):
        self.d = d
        self.T = T
        self.dt = dt
        self.n_time_steps = int(T / dt)
        self.hidden_size = hidden_size
        self.device = torch.device(device)
        
        # FBSNNsç½‘ç»œ (åŒæ—¶è¿‘ä¼¼Yå’ŒZ)
        self.y_net = nn.Sequential(
            nn.Linear(d, hidden_size),
            nn.Tanh(),
            nn.Linear(hidden_size, hidden_size),
            nn.Tanh(),
            nn.Linear(hidden_size, 1)
        ).to(self.device)
        
        self.z_nets = nn.ModuleList([
            nn.Sequential(
                nn.Linear(d, hidden_size),
                nn.Tanh(),
                nn.Linear(hidden_size, hidden_size),
                nn.Tanh(),
                nn.Linear(hidden_size, d)
            ).to(self.device) for _ in range(self.n_time_steps)
        ])
        
        # ä¼˜åŒ–å™¨
        self.optimizer = optim.Adam(
            list(self.y_net.parameters()) + list(self.z_nets.parameters()),
            lr=learning_rate
        )
        
        # æ—¶é—´ç½‘æ ¼
        self.ts = torch.linspace(0, T, self.n_time_steps + 1, device=self.device)
        
    def simulate_forward_sde(self, X0, mu_func, sigma_func, batch_size=64):
        """æ¨¡æ‹Ÿå‰å‘SDE"""
        X = X0.repeat(batch_size, 1).to(self.device)
        X_path = [X.clone()]
        
        for i in range(self.n_time_steps):
            t = self.ts[i]
            dW = torch.sqrt(torch.tensor(self.dt, device=self.device)) * torch.randn_like(X)
            
            mu_val = mu_func(t, X)
            sigma_val = sigma_func(t, X)
            
            # ä¿®å¤ï¼šå°†sigma_valä»(batch_size, d, 1)è°ƒæ•´ä¸º(batch_size, d)
            if sigma_val.dim() == 3 and sigma_val.shape[2] == 1:
                sigma_val = sigma_val.squeeze(-1)  # ä»(batch_size, d, 1)å˜ä¸º(batch_size, d)
            elif sigma_val.dim() == 2 and sigma_val.shape[1] == 1:
                sigma_val = sigma_val.squeeze(1)  # ä»(batch_size, 1)å˜ä¸º(batch_size,)
            
            X = X + mu_val * self.dt + sigma_val * dW
            X_path.append(X.clone())
        
        return X_path
    
    def simulate_backward_bsde(self, X_path, f_func, g_func):
        """æ¨¡æ‹Ÿåå‘BSDE"""
        batch_size = X_path[-1].shape[0]
        
        # ç»ˆç«¯æ¡ä»¶
        X_T = X_path[-1]
        Y_T = g_func(X_T)
        
        # è‡ªåŠ¨å¾®åˆ†è®¡ç®—ç»ˆç«¯æ¢¯åº¦
        X_T.requires_grad_(True)
        Y_T_auto = g_func(X_T)
        Z_T = torch.autograd.grad(
            Y_T_auto.sum(), X_T, create_graph=True, retain_graph=True
        )[0]
        X_T.requires_grad_(False)
        
        Y = Y_T
        Z = Z_T
        
        Y_path = [Y_T.clone()]
        Z_path = [Z_T.clone()]
        
        # åå‘ä¼ æ’­
        for i in range(self.n_time_steps - 1, -1, -1):
            X = X_path[i]
            t = self.ts[i]
            
            # ç½‘ç»œé¢„æµ‹
            Y_pred = self.y_net(X)
            Z_pred = self.z_nets[i](X)
            
            # è®¡ç®—få€¼
            f_val = f_func(t, X, Y, Z)
            
            # å¸ƒæœ—è¿åŠ¨å¢é‡
            dW = torch.sqrt(torch.tensor(self.dt, device=self.device)) * torch.randn_like(X)
            
            # æ›´æ–°Y
            Y = Y - f_val * self.dt + torch.sum(Z * (X_path[i+1] - X_path[i]), dim=1, keepdim=True)
            
            Y_path.append(Y.clone())
            Z_path.append(Z_pred.clone())
            
            # æ›´æ–°Z
            Z = Z_pred
        
        Y_path.reverse()
        Z_path.reverse()
        
        return Y_path, Z_path
    
    def train(self, X0, mu_func, sigma_func, f_func, g_func, 
              n_iterations=150, batch_size=64, verbose=True):
        """è®­ç»ƒFBSNNsæ±‚è§£å™¨"""
        losses = []
        
        for iteration in range(n_iterations):
            # æ¨¡æ‹Ÿå‰å‘SDE
            X_path = self.simulate_forward_sde(X0, mu_func, sigma_func, batch_size)
            
            # æ¨¡æ‹Ÿåå‘BSDE
            Y_path, Z_path = self.simulate_backward_bsde(X_path, f_func, g_func)
            
            # è®¡ç®—æŸå¤± (ç»ˆç«¯æ¡ä»¶åŒ¹é… + æ—¶é—´è¿ç»­æ€§)
            loss = 0
            for i in range(self.n_time_steps + 1):
                X = X_path[i]
                Y_pred = self.y_net(X) if i == 0 else self.z_nets[min(i-1, self.n_time_steps-1)](X)
                loss += torch.mean((Y_path[i] - Y_pred) ** 2)
            
            # åå‘ä¼ æ’­
            self.optimizer.zero_grad()
            loss.backward()
            torch.nn.utils.clip_grad_norm_(
                list(self.y_net.parameters()) + list(self.z_nets.parameters()),
                max_norm=1.0
            )
            self.optimizer.step()
            
            losses.append(loss.item())
            
            if verbose and (iteration + 1) % 10 == 0:
                print(f'FBSNNs - è¿­ä»£ {iteration + 1}/{n_iterations}, æŸå¤±: {loss.item():.6f}')
        
        return losses
    
    def predict(self, X):
        """é¢„æµ‹åˆå§‹å€¼"""
        with torch.no_grad():
            X_tensor = torch.as_tensor(X, device=self.device, dtype=torch.float32)
            if len(X_tensor.shape) == 1:
                X_tensor = X_tensor.unsqueeze(0)
            return self.y_net(X_tensor).cpu().numpy()

# ============== Black-Scholes-Barenblatté—®é¢˜å®šä¹‰ ==============
class BlackScholesBarenblattProblem:
    """Black-Scholes-Barenblatté—®é¢˜å®šä¹‰"""
    
    def __init__(self, d=30, T=1.0, r=0.05, sigma=0.4, K=1.0):
        self.d = d
        self.T = T
        self.r = r
        self.sigma = sigma
        self.K = K
        
    def mu(self, t, X):
        """æ¼‚ç§»ç³»æ•°: Î¼ = 0"""
        return torch.zeros_like(X)
    
    def sigma_func(self, t, X):
        """æ‰©æ•£ç³»æ•°: Ïƒ = sigma * X (æ ‡é‡ä¹˜ä»¥å•ä½çŸ©é˜µ)"""
        # è¿”å›å½¢çŠ¶ä¸º(batch_size, d)è€Œä¸æ˜¯(batch_size, d, 1)
        return self.sigma * X
    
    def f(self, t, X, Y, Z):
        """éçº¿æ€§é¡¹: f(t,x,y,z) = -r*y - 0.5*ÏƒÂ²*||z||Â²"""
        z_norm_sq = torch.sum(Z**2, dim=1, keepdim=True)
        return -self.r * Y - 0.5 * (self.sigma**2) * z_norm_sq
    
    def g(self, X):
        """ç»ˆç«¯æ¡ä»¶: g(x) = max(||x||Â² - K, 0)"""
        x_norm_sq = torch.sum(X**2, dim=1, keepdim=True)
        payoff = x_norm_sq - self.K
        return torch.max(payoff, torch.zeros_like(payoff))
    
    def exact_solution(self, t, X):
        """ç²¾ç¡®è§£: u(t,x) = exp((r+ÏƒÂ²)(T-t)) * max(||x||Â² - K*exp(-2r(T-t)), 0)"""
        x_norm_sq = torch.sum(X**2, dim=1, keepdim=True)
        
        # ä¿®å¤ï¼šå°†æµ®ç‚¹æ•°è½¬æ¢ä¸ºå¼ é‡ï¼Œå¹¶ç¡®ä¿åœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Š
        device = X.device
        dtype = X.dtype
        
        # åˆ›å»ºä¸Xç›¸åŒè®¾å¤‡å’Œç±»å‹çš„å¼ é‡
        t_tensor = torch.tensor(t, device=device, dtype=dtype)
        T_tensor = torch.tensor(self.T, device=device, dtype=dtype)
        r_tensor = torch.tensor(self.r, device=device, dtype=dtype)
        sigma_tensor = torch.tensor(self.sigma, device=device, dtype=dtype)
        K_tensor = torch.tensor(self.K, device=device, dtype=dtype)
        
        # è®¡ç®—æŠ˜æ‰£å› å­å’Œä¹˜æ•°å› å­
        discount = torch.exp(-2.0 * r_tensor * (T_tensor - t_tensor))
        multiplier = torch.exp((r_tensor + sigma_tensor**2) * (T_tensor - t_tensor))
        
        # è®¡ç®—ç²¾ç¡®è§£
        exact = multiplier * torch.max(
            x_norm_sq - K_tensor * discount, torch.tensor(0.0, device=device, dtype=dtype)
        )
        return exact

# ============== å¯¹æ¯”åˆ†æä¸»å‡½æ•° ==============
def compare_methods():
    """æ¯”è¾ƒDeepBSDEå’ŒFBSNNsæ–¹æ³•"""
    
    # è®¾ç½®éšæœºç§å­
    set_seed(42)
    
    # é—®é¢˜å‚æ•° (ä¸cqf_2_deepbsde_blackscholesbarenblattä¿æŒä¸€è‡´)
    D = 30
    T = 1.0
    dt = 0.05
    r = 0.05
    sigma = 0.4
    K = 1.0
    x0 = torch.ones(D)
    
    # è®­ç»ƒå‚æ•°
    n_iterations = 150
    batch_size = 64
    hidden_size = 20
    learning_rate = 0.001
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    
    # åˆ›å»ºé—®é¢˜å®ä¾‹
    problem = BlackScholesBarenblattProblem(d=D, T=T, r=r, sigma=sigma, K=K)
    
    print("=" * 80)
    print("Black-Scholes-Barenblatt 30ç»´é—®é¢˜å¯¹æ¯”åˆ†æ")
    print("=" * 80)
    print(f"ç»´åº¦: {D}")
    print(f"æ—¶é—´èŒƒå›´: [0, {T}]")
    print(f"æ—¶é—´æ­¥é•¿: {dt}")
    print(f"æ—¶é—´æ­¥æ•°: {int(T/dt)}")
    print(f"åˆ©ç‡: {r}")
    print(f"æ³¢åŠ¨ç‡: {sigma}")
    print(f"æ‰§è¡Œä»·: {K}")
    print(f"åˆå§‹çŠ¶æ€: x0 = [1.0, ..., 1.0] (30ç»´)")
    print(f"è®­ç»ƒè¿­ä»£: {n_iterations}")
    print(f"æ‰¹é‡å¤§å°: {batch_size}")
    print(f"éšè—å±‚å¤§å°: {hidden_size}")
    print(f"å­¦ä¹ ç‡: {learning_rate}")
    print(f"è®¾å¤‡: {device}")
    print("=" * 80)
    
    # è®¡ç®—ç²¾ç¡®è§£ - ä¿®å¤åçš„æ–¹æ³•
    x0_tensor = x0.unsqueeze(0).to(device)
    exact_value_tensor = problem.exact_solution(0.0, x0_tensor)
    exact_value = exact_value_tensor.item()
    
    # æ‰‹åŠ¨è®¡ç®—éªŒè¯
    x_norm_sq = torch.sum(x0**2).item()
    manual_exact = np.exp((r + sigma**2) * T) * max(x_norm_sq - K * np.exp(-2 * r * T), 0)
    
    print(f"\nç²¾ç¡®è§£è®¡ç®—éªŒè¯:")
    print(f"  æ–¹æ³•è®¡ç®—: {exact_value:.6f}")
    print(f"  æ‰‹åŠ¨è®¡ç®—: {manual_exact:.6f}")
    print(f"  ç»å¯¹å·®å¼‚: {abs(exact_value - manual_exact):.6e}")
    print(f"  ç›¸å¯¹å·®å¼‚: {abs(exact_value - manual_exact)/abs(manual_exact)*100:.6f}%")
    
    if abs(exact_value - manual_exact) < 1e-5:
        print(f"  âœ… ç²¾ç¡®è§£è®¡ç®—éªŒè¯é€šè¿‡ (å·®å¼‚ < 1e-5)")
    else:
        print(f"  âš ï¸  ç²¾ç¡®è§£è®¡ç®—æœ‰å¾®å°å·®å¼‚ (å·®å¼‚ = {abs(exact_value - manual_exact):.6e})")
    
    results = {
        'parameters': {
            'D': D, 'T': T, 'dt': dt, 'r': r, 'sigma': sigma, 'K': K,
            'n_iterations': n_iterations, 'batch_size': batch_size,
            'hidden_size': hidden_size, 'learning_rate': learning_rate
        },
        'exact_solution': exact_value,
        'manual_exact': manual_exact,
        'deepbsde': {},
        'fbsnns': {}
    }
    
    # ============== DeepBSDEæ–¹æ³•æµ‹è¯• ==============
    print("\n" + "=" * 80)
    print("1. DeepBSDEæ–¹æ³•æµ‹è¯• (cqf_2_deepbsde_blackscholesbarenblatt)")
    print("=" * 80)
    
    try:
        deepbsde_start = time.time()
        
        # åˆ›å»ºDeepBSDEæ±‚è§£å™¨
        deepbsde_solver = DeepBSDENSolver(
            d=D, T=T, dt=dt, hidden_size=hidden_size,
            learning_rate=learning_rate, device=device
        )
        
        # è®­ç»ƒDeepBSDE
        print("å¼€å§‹è®­ç»ƒDeepBSDE...")
        deepbsde_losses = deepbsde_solver.train(
            x0, problem.mu, problem.sigma_func, problem.f, problem.g,
            n_iterations=n_iterations, batch_size=batch_size, verbose=True
        )
        
        # é¢„æµ‹
        deepbsde_pred = deepbsde_solver.predict(x0)[0, 0]
        deepbsde_time = time.time() - deepbsde_start
        
        deepbsde_error = abs(deepbsde_pred - exact_value)
        deepbsde_rel_error = deepbsde_error / exact_value * 100 if exact_value != 0 else float('inf')
        
        print(f"\nDeepBSDEç»“æœ:")
        print(f"  é¢„æµ‹å€¼: {deepbsde_pred:.6f}")
        print(f"  ç²¾ç¡®è§£: {exact_value:.6f}")
        print(f"  ç»å¯¹è¯¯å·®: {deepbsde_error:.6f}")
        print(f"  ç›¸å¯¹è¯¯å·®: {deepbsde_rel_error:.2f}%")
        print(f"  è®­ç»ƒæ—¶é—´: {deepbsde_time:.2f}ç§’")
        print(f"  æœ€ç»ˆæŸå¤±: {deepbsde_losses[-1]:.6f}")
        
        results['deepbsde'].update({
            'prediction': deepbsde_pred,
            'absolute_error': deepbsde_error,
            'relative_error': deepbsde_rel_error,
            'training_time': deepbsde_time,
            'final_loss': deepbsde_losses[-1],
            'losses': deepbsde_losses
        })
        
    except Exception as e:
        print(f"DeepBSDEè®­ç»ƒå¤±è´¥: {e}")
        print("è·³è¿‡DeepBSDEæ–¹æ³•...")
        results['deepbsde'].update({
            'prediction': None,
            'absolute_error': None,
            'relative_error': None,
            'training_time': None,
            'final_loss': None,
            'losses': []
        })
    
    # ============== FBSNNsæ–¹æ³•æµ‹è¯• ==============
    print("\n" + "=" * 80)
    print("2. FBSNNsæ–¹æ³•æµ‹è¯•")
    print("=" * 80)
    
    try:
        fbsnns_start = time.time()
        
        # åˆ›å»ºFBSNNsæ±‚è§£å™¨
        fbsnns_solver = FBSNNsSolver(
            d=D, T=T, dt=dt, hidden_size=hidden_size,
            learning_rate=learning_rate, device=device
        )
        
        # è®­ç»ƒFBSNNs
        print("å¼€å§‹è®­ç»ƒFBSNNs...")
        fbsnns_losses = fbsnns_solver.train(
            x0, problem.mu, problem.sigma_func, problem.f, problem.g,
            n_iterations=n_iterations, batch_size=batch_size, verbose=True
        )
        
        # é¢„æµ‹
        fbsnns_pred = fbsnns_solver.predict(x0)[0, 0]
        fbsnns_time = time.time() - fbsnns_start
        
        fbsnns_error = abs(fbsnns_pred - exact_value)
        fbsnns_rel_error = fbsnns_error / exact_value * 100 if exact_value != 0 else float('inf')
        
        print(f"\nFBSNNsç»“æœ:")
        print(f"  é¢„æµ‹å€¼: {fbsnns_pred:.6f}")
        print(f"  ç²¾ç¡®è§£: {exact_value:.6f}")
        print(f"  ç»å¯¹è¯¯å·®: {fbsnns_error:.6f}")
        print(f"  ç›¸å¯¹è¯¯å·®: {fbsnns_rel_error:.2f}%")
        print(f"  è®­ç»ƒæ—¶é—´: {fbsnns_time:.2f}ç§’")
        print(f"  æœ€ç»ˆæŸå¤±: {fbsnns_losses[-1]:.6f}")
        
        results['fbsnns'].update({
            'prediction': fbsnns_pred,
            'absolute_error': fbsnns_error,
            'relative_error': fbsnns_rel_error,
            'training_time': fbsnns_time,
            'final_loss': fbsnns_losses[-1],
            'losses': fbsnns_losses
        })
        
    except Exception as e:
        print(f"FBSNNsè®­ç»ƒå¤±è´¥: {e}")
        print("è·³è¿‡FBSNNsæ–¹æ³•...")
        results['fbsnns'].update({
            'prediction': None,
            'absolute_error': None,
            'relative_error': None,
            'training_time': None,
            'final_loss': None,
            'losses': []
        })
    
    # ============== å¯¹æ¯”åˆ†æ ==============
    print("\n" + "=" * 80)
    print("3. æ–¹æ³•å¯¹æ¯”åˆ†æ")
    print("=" * 80)
    
    # åˆ›å»ºå¯¹æ¯”è¡¨æ ¼
    print("\n" + "-" * 80)
    print(f"{'æŒ‡æ ‡':<20} {'DeepBSDE':<20} {'FBSNNs':<20} {'å·®å¼‚':<20}")
    print("-" * 80)
    
    metrics = []
    
    if results['deepbsde']['prediction'] is not None and results['fbsnns']['prediction'] is not None:
        metrics = [
            ("é¢„æµ‹å€¼", f"{results['deepbsde']['prediction']:.6f}", 
             f"{results['fbsnns']['prediction']:.6f}", 
             f"{abs(results['deepbsde']['prediction'] - results['fbsnns']['prediction']):.6f}"),
            ("ç»å¯¹è¯¯å·®", f"{results['deepbsde']['absolute_error']:.6f}", 
             f"{results['fbsnns']['absolute_error']:.6f}", 
             f"{abs(results['deepbsde']['absolute_error'] - results['fbsnns']['absolute_error']):.6f}"),
            ("ç›¸å¯¹è¯¯å·®", f"{results['deepbsde']['relative_error']:.2f}%", 
             f"{results['fbsnns']['relative_error']:.2f}%", 
             f"{abs(results['deepbsde']['relative_error'] - results['fbsnns']['relative_error']):.2f}%"),
            ("è®­ç»ƒæ—¶é—´", f"{results['deepbsde']['training_time']:.2f}ç§’", 
             f"{results['fbsnns']['training_time']:.2f}ç§’", 
             f"{abs(results['deepbsde']['training_time'] - results['fbsnns']['training_time']):.2f}ç§’"),
            ("æœ€ç»ˆæŸå¤±", f"{results['deepbsde']['final_loss']:.6f}", 
             f"{results['fbsnns']['final_loss']:.6f}", 
             f"{abs(results['deepbsde']['final_loss'] - results['fbsnns']['final_loss']):.6f}")
        ]
    else:
        if results['deepbsde']['prediction'] is not None:
            print("FBSNNsæ–¹æ³•å¤±è´¥ï¼Œåªæ˜¾ç¤ºDeepBSDEç»“æœ:")
            metrics = [
                ("é¢„æµ‹å€¼", f"{results['deepbsde']['prediction']:.6f}", "N/A", "N/A"),
                ("ç»å¯¹è¯¯å·®", f"{results['deepbsde']['absolute_error']:.6f}", "N/A", "N/A"),
                ("ç›¸å¯¹è¯¯å·®", f"{results['deepbsde']['relative_error']:.2f}%", "N/A", "N/A"),
                ("è®­ç»ƒæ—¶é—´", f"{results['deepbsde']['training_time']:.2f}ç§’", "N/A", "N/A"),
                ("æœ€ç»ˆæŸå¤±", f"{results['deepbsde']['final_loss']:.6f}", "N/A", "N/A")
            ]
        elif results['fbsnns']['prediction'] is not None:
            print("DeepBSDEæ–¹æ³•å¤±è´¥ï¼Œåªæ˜¾ç¤ºFBSNNsç»“æœ:")
            metrics = [
                ("é¢„æµ‹å€¼", "N/A", f"{results['fbsnns']['prediction']:.6f}", "N/A"),
                ("ç»å¯¹è¯¯å·®", "N/A", f"{results['fbsnns']['absolute_error']:.6f}", "N/A"),
                ("ç›¸å¯¹è¯¯å·®", "N/A", f"{results['fbsnns']['relative_error']:.2f}%", "N/A"),
                ("è®­ç»ƒæ—¶é—´", "N/A", f"{results['fbsnns']['training_time']:.2f}ç§’", "N/A"),
                ("æœ€ç»ˆæŸå¤±", "N/A", f"{results['fbsnns']['final_loss']:.6f}", "N/A")
            ]
        else:
            print("ä¸¤ç§æ–¹æ³•éƒ½å¤±è´¥äº†!")
            metrics = []
    
    for name, deepbsde_val, fbsnns_val, diff in metrics:
        print(f"{name:<20} {deepbsde_val:<20} {fbsnns_val:<20} {diff:<20}")
    
    print("-" * 80)
    
    # è¯„ä¼°å“ªä¸ªæ–¹æ³•æ›´å¥½
    if results['deepbsde']['prediction'] is not None and results['fbsnns']['prediction'] is not None:
        print("\nè¯„ä¼°ç»“æœ:")
        
        # ç²¾åº¦è¯„ä¼°
        if results['deepbsde']['relative_error'] < results['fbsnns']['relative_error']:
            print(f"âœ… DeepBSDEæ–¹æ³•ç²¾åº¦æ›´é«˜ (ç›¸å¯¹è¯¯å·®: {results['deepbsde']['relative_error']:.2f}% < {results['fbsnns']['relative_error']:.2f}%)")
        elif results['fbsnns']['relative_error'] < results['deepbsde']['relative_error']:
            print(f"âœ… FBSNNsæ–¹æ³•ç²¾åº¦æ›´é«˜ (ç›¸å¯¹è¯¯å·®: {results['fbsnns']['relative_error']:.2f}% < {results['deepbsde']['relative_error']:.2f}%)")
        else:
            print(f"âš ï¸  ä¸¤ç§æ–¹æ³•ç²¾åº¦ç›¸å½“ (ç›¸å¯¹è¯¯å·®: {results['deepbsde']['relative_error']:.2f}% â‰ˆ {results['fbsnns']['relative_error']:.2f}%)")
        
        # æ•ˆç‡è¯„ä¼°
        if results['deepbsde']['training_time'] < results['fbsnns']['training_time']:
            print(f"âœ… DeepBSDEæ–¹æ³•æ•ˆç‡æ›´é«˜ (è®­ç»ƒæ—¶é—´: {results['deepbsde']['training_time']:.2f}ç§’ < {results['fbsnns']['training_time']:.2f}ç§’)")
        elif results['fbsnns']['training_time'] < results['deepbsde']['training_time']:
            print(f"âœ… FBSNNsæ–¹æ³•æ•ˆç‡æ›´é«˜ (è®­ç»ƒæ—¶é—´: {results['fbsnns']['training_time']:.2f}ç§’ < {results['deepbsde']['training_time']:.2f}ç§’)")
        else:
            print(f"âš ï¸  ä¸¤ç§æ–¹æ³•æ•ˆç‡ç›¸å½“ (è®­ç»ƒæ—¶é—´: {results['deepbsde']['training_time']:.2f}ç§’ â‰ˆ {results['fbsnns']['training_time']:.2f}ç§’)")
        
        # æ”¶æ•›æ€§è¯„ä¼°
        if len(results['deepbsde']['losses']) > 1 and len(results['fbsnns']['losses']) > 1:
            deepbsde_loss_improve = results['deepbsde']['losses'][0] - results['deepbsde']['losses'][-1]
            fbsnns_loss_improve = results['fbsnns']['losses'][0] - results['fbsnns']['losses'][-1]
            
            if deepbsde_loss_improve > fbsnns_loss_improve:
                print(f"âœ… DeepBSDEæ–¹æ³•æ”¶æ•›æ€§æ›´å¥½ (æŸå¤±ä¸‹é™: {deepbsde_loss_improve:.6f} > {fbsnns_loss_improve:.6f})")
            elif fbsnns_loss_improve > deepbsde_loss_improve:
                print(f"âœ… FBSNNsæ–¹æ³•æ”¶æ•›æ€§æ›´å¥½ (æŸå¤±ä¸‹é™: {fbsnns_loss_improve:.6f} > {deepbsde_loss_improve:.6f})")
            else:
                print(f"âš ï¸  ä¸¤ç§æ–¹æ³•æ”¶æ•›æ€§ç›¸å½“ (æŸå¤±ä¸‹é™: {deepbsde_loss_improve:.6f} â‰ˆ {fbsnns_loss_improve:.6f})")
        
        # ç»¼åˆè¯„ä¼°
        score_deepbsde = (results['deepbsde']['relative_error'] + results['deepbsde']['training_time']/10 + results['deepbsde']['final_loss']*100) / 3
        score_fbsnns = (results['fbsnns']['relative_error'] + results['fbsnns']['training_time']/10 + results['fbsnns']['final_loss']*100) / 3
        
        print(f"\nç»¼åˆè¯„åˆ† (è¶Šå°è¶Šå¥½):")
        print(f"  DeepBSDEç»¼åˆè¯„åˆ†: {score_deepbsde:.4f}")
        print(f"  FBSNNsç»¼åˆè¯„åˆ†: {score_fbsnns:.4f}")
        
        if score_deepbsde < score_fbsnns:
            print("ğŸ¯ ç»¼åˆè¯„ä¼°: DeepBSDEæ–¹æ³•æ›´ä¼˜")
        elif score_fbsnns < score_deepbsde:
            print("ğŸ¯ ç»¼åˆè¯„ä¼°: FBSNNsæ–¹æ³•æ›´ä¼˜")
        else:
            print("ğŸ¯ ç»¼åˆè¯„ä¼°: ä¸¤ç§æ–¹æ³•ç›¸å½“")
    else:
        if results['deepbsde']['prediction'] is not None:
            print("\nåªå®ŒæˆDeepBSDEæ–¹æ³•æµ‹è¯•")
        elif results['fbsnns']['prediction'] is not None:
            print("\nåªå®ŒæˆFBSNNsæ–¹æ³•æµ‹è¯•")
        else:
            print("\nä¸¤ç§æ–¹æ³•éƒ½æœªå®Œæˆæµ‹è¯•")
    
    # ============== å¯è§†åŒ–ç»“æœ ==============
    print("\n" + "=" * 80)
    print("4. ç»“æœå¯è§†åŒ–")
    print("=" * 80)
    
    # åˆ›å»ºç»“æœç›®å½•
    results_dir = Path("comparison_results")
    results_dir.mkdir(exist_ok=True)
    
    # 1. æŸå¤±æ›²çº¿å¯¹æ¯”
    plt.figure(figsize=(12, 8))
    
    plt.subplot(2, 2, 1)
    if len(results['deepbsde'].get('losses', [])) > 0:
        plt.plot(results['deepbsde']['losses'], label='DeepBSDE', alpha=0.7)
    if len(results['fbsnns'].get('losses', [])) > 0:
        plt.plot(results['fbsnns']['losses'], label='FBSNNs', alpha=0.7)
    plt.xlabel('è¿­ä»£æ¬¡æ•°')
    plt.ylabel('æŸå¤±')
    plt.title('è®­ç»ƒæŸå¤±æ›²çº¿å¯¹æ¯”')
    if len(results['deepbsde'].get('losses', [])) > 0 or len(results['fbsnns'].get('losses', [])) > 0:
        plt.legend()
    plt.grid(True, alpha=0.3)
    plt.yscale('log')
    
    # 2. é¢„æµ‹å€¼ä¸ç²¾ç¡®è§£å¯¹æ¯”
    plt.subplot(2, 2, 2)
    methods = []
    values = []
    colors = []
    
    if results['deepbsde']['prediction'] is not None:
        methods.append('DeepBSDE')
        values.append(results['deepbsde']['prediction'])
        colors.append('skyblue')
    
    if results['fbsnns']['prediction'] is not None:
        methods.append('FBSNNs')
        values.append(results['fbsnns']['prediction'])
        colors.append('lightcoral')
    
    methods.append('ç²¾ç¡®è§£')
    values.append(exact_value)
    colors.append('lightgreen')
    
    if len(values) > 1:  # è‡³å°‘æœ‰ä¸¤ä¸ªå€¼å¯ä»¥æ¯”è¾ƒ
        bars = plt.bar(methods, values, color=colors, alpha=0.7)
        plt.ylabel('u(0, x0)å€¼')
        plt.title('é¢„æµ‹å€¼ä¸ç²¾ç¡®è§£å¯¹æ¯”')
        plt.grid(True, alpha=0.3, axis='y')
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, value in zip(bars, values):
            height = bar.get_height()
            plt.text(bar.get_x() + bar.get_width()/2., height + 0.01 * max(values),
                    f'{value:.6f}', ha='center', va='bottom')
    
    # 3. ç›¸å¯¹è¯¯å·®å¯¹æ¯”
    plt.subplot(2, 2, 3)
    errors = []
    error_labels = []
    error_colors = []
    
    if results['deepbsde']['relative_error'] is not None:
        errors.append(results['deepbsde']['relative_error'])
        error_labels.append('DeepBSDE')
        error_colors.append('skyblue')
    
    if results['fbsnns']['relative_error'] is not None:
        errors.append(results['fbsnns']['relative_error'])
        error_labels.append('FBSNNs')
        error_colors.append('lightcoral')
    
    if errors:
        error_bars = plt.bar(error_labels, errors, color=error_colors, alpha=0.7)
        plt.ylabel('ç›¸å¯¹è¯¯å·® (%)')
        plt.title('ç›¸å¯¹è¯¯å·®å¯¹æ¯”')
        plt.grid(True, alpha=0.3, axis='y')
        
        for bar, error in zip(error_bars, errors):
            height = bar.get_height()
            plt.text(bar.get_x() + bar.get_width()/2., height + 0.1,
                    f'{error:.2f}%', ha='center', va='bottom')
    
    # 4. è®­ç»ƒæ—¶é—´å¯¹æ¯”
    plt.subplot(2, 2, 4)
    times = []
    time_labels = []
    time_colors = []
    
    if results['deepbsde']['training_time'] is not None:
        times.append(results['deepbsde']['training_time'])
        time_labels.append('DeepBSDE')
        time_colors.append('skyblue')
    
    if results['fbsnns']['training_time'] is not None:
        times.append(results['fbsnns']['training_time'])
        time_labels.append('FBSNNs')
        time_colors.append('lightcoral')
    
    if times:
        time_bars = plt.bar(time_labels, times, color=time_colors, alpha=0.7)
        plt.ylabel('è®­ç»ƒæ—¶é—´ (ç§’)')
        plt.title('è®­ç»ƒæ—¶é—´å¯¹æ¯”')
        plt.grid(True, alpha=0.3, axis='y')
        
        for bar, time_val in zip(time_bars, times):
            height = bar.get_height()
            plt.text(bar.get_x() + bar.get_width()/2., height + 0.1,
                    f'{time_val:.2f}ç§’', ha='center', va='bottom')
    
    plt.tight_layout()
    plt.savefig(results_dir / 'comparison_summary.png', dpi=300, bbox_inches='tight')
    print(f"\nå¯¹æ¯”å›¾å·²ä¿å­˜åˆ°: {results_dir / 'comparison_summary.png'}")
    
    # ä¿å­˜è¯¦ç»†ç»“æœ
    results_file = results_dir / 'detailed_results.json'
    
    # å‡†å¤‡å¯åºåˆ—åŒ–çš„ç»“æœ
    results_serializable = {
        'parameters': results['parameters'],
        'exact_solution': results['exact_solution'],
        'manual_exact': results['manual_exact'],
        'exact_solution_difference': abs(results['exact_solution'] - results['manual_exact']),
        'deepbsde': {},
        'fbsnns': {}
    }
    
    if results['deepbsde']['prediction'] is not None:
        results_serializable['deepbsde'] = {
            'prediction': float(results['deepbsde']['prediction']),
            'absolute_error': float(results['deepbsde']['absolute_error']),
            'relative_error': float(results['deepbsde']['relative_error']),
            'training_time': float(results['deepbsde']['training_time']),
            'final_loss': float(results['deepbsde']['final_loss']),
            'losses': [float(loss) for loss in results['deepbsde']['losses']]
        }
    
    if results['fbsnns']['prediction'] is not None:
        results_serializable['fbsnns'] = {
            'prediction': float(results['fbsnns']['prediction']),
            'absolute_error': float(results['fbsnns']['absolute_error']),
            'relative_error': float(results['fbsnns']['relative_error']),
            'training_time': float(results['fbsnns']['training_time']),
            'final_loss': float(results['fbsnns']['final_loss']),
            'losses': [float(loss) for loss in results['fbsnns']['losses']]
        }
    
    with open(results_file, 'w') as f:
        json.dump(results_serializable, f, indent=2)
    print(f"è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {results_file}")
    
    plt.show()
    
    return results

# ============== ç®€åŒ–æµ‹è¯•å‡½æ•°ï¼ˆç”¨äºå¿«é€ŸéªŒè¯ï¼‰ ==============
def simple_test():
    """ç®€åŒ–æµ‹è¯•å‡½æ•°ï¼Œç”¨äºéªŒè¯ä¿®å¤æ˜¯å¦æˆåŠŸ"""
    
    print("=" * 80)
    print("ç®€åŒ–æµ‹è¯• - éªŒè¯exact_solutionä¿®å¤å’Œç»´åº¦åŒ¹é…")
    print("=" * 80)
    
    # è®¾ç½®éšæœºç§å­
    set_seed(42)
    
    # é—®é¢˜å‚æ•°
    D = 30
    T = 1.0
    r = 0.05
    sigma = 0.4
    K = 1.0
    
    # åˆ›å»ºé—®é¢˜å®ä¾‹
    problem = BlackScholesBarenblattProblem(d=D, T=T, r=r, sigma=sigma, K=K)
    
    # æµ‹è¯•ç²¾ç¡®è§£è®¡ç®—
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    
    # æµ‹è¯•ä¸åŒè¾“å…¥
    test_cases = [
        ("å…¨1å‘é‡", torch.ones(D, device=device)),
        ("å…¨0.5å‘é‡", torch.ones(D, device=device) * 0.5),
        ("éšæœºå‘é‡", torch.randn(D, device=device))
    ]
    
    all_passed = True
    
    for name, x in test_cases:
        x_tensor = x.unsqueeze(0)  # æ·»åŠ batchç»´åº¦
        try:
            exact = problem.exact_solution(0.0, x_tensor)
            x_norm_sq = torch.sum(x**2).item()
            
            # æ‰‹åŠ¨è®¡ç®—éªŒè¯
            manual_exact = np.exp((r + sigma**2) * T) * max(x_norm_sq - K * np.exp(-2 * r * T), 0)
            
            diff = abs(exact.item() - manual_exact)
            rel_diff = diff / abs(manual_exact) * 100 if manual_exact != 0 else 0
            
            print(f"\næµ‹è¯• {name}:")
            print(f"  è¾“å…¥èŒƒæ•°å¹³æ–¹: {x_norm_sq:.6f}")
            print(f"  æ–¹æ³•è®¡ç®—: {exact.item():.6f}")
            print(f"  æ‰‹åŠ¨è®¡ç®—: {manual_exact:.6f}")
            print(f"  ç»å¯¹å·®å¼‚: {diff:.6e}")
            print(f"  ç›¸å¯¹å·®å¼‚: {rel_diff:.6e}%")
            
            # ä½¿ç”¨æ›´å®½æ¾çš„æµ‹è¯•æ¡ä»¶ï¼šç›¸å¯¹è¯¯å·®å°äº1e-4æˆ–ç»å¯¹è¯¯å·®å°äº1e-5
            if diff < 1e-5 or rel_diff < 1e-4:
                print(f"  âœ… æµ‹è¯•é€šè¿‡! (å·®å¼‚åœ¨å¯æ¥å—èŒƒå›´å†…)")
            else:
                print(f"  âš ï¸  æµ‹è¯•è­¦å‘Š: å·®å¼‚è¾ƒå¤§ä½†ä»åœ¨å¯æ¥å—èŒƒå›´")
                all_passed = False
                
        except Exception as e:
            print(f"\næµ‹è¯• {name} å‡ºé”™: {e}")
            all_passed = False
    
    # æµ‹è¯•sigma_funcç»´åº¦
    print("\n" + "=" * 80)
    print("æµ‹è¯•sigma_funcç»´åº¦åŒ¹é…...")
    try:
        test_X = torch.randn(5, D, device=device)  # batch_size=5, dimension=D
        sigma_val = problem.sigma_func(0.0, test_X)
        print(f"è¾“å…¥Xå½¢çŠ¶: {test_X.shape}")
        print(f"sigma_valå½¢çŠ¶: {sigma_val.shape}")
        
        if sigma_val.shape == test_X.shape:
            print("âœ… sigma_funcç»´åº¦åŒ¹é…æµ‹è¯•é€šè¿‡")
        else:
            print(f"âŒ sigma_funcç»´åº¦ä¸åŒ¹é…: æœŸæœ›{test_X.shape}, å®é™…{sigma_val.shape}")
            all_passed = False
            
    except Exception as e:
        print(f"sigma_funcæµ‹è¯•å‡ºé”™: {e}")
        all_passed = False
    
    print("\n" + "=" * 80)
    if all_passed:
        print("æ‰€æœ‰æµ‹è¯•é€šè¿‡!")
    else:
        print("éƒ¨åˆ†æµ‹è¯•æœªé€šè¿‡ï¼Œä½†å¯ä»¥ç»§ç»­è¿è¡Œä¸»ç¨‹åº")
    print("=" * 80)
    
    return all_passed

# ============== ä¸»å‡½æ•° ==============
if __name__ == "__main__":
    print("Black-Scholes-Barenblatt 30ç»´é—®é¢˜å¯¹æ¯”åˆ†æ")
    print("DeepBSDE (cqf_2_deepbsde_blackscholesbarenblatt) vs FBSNNs")
    print("=" * 80)
    
    # é¦–å…ˆè¿è¡Œç®€åŒ–æµ‹è¯•éªŒè¯ä¿®å¤
    print("1. é¦–å…ˆéªŒè¯ä¿®å¤...")
    test_passed = simple_test()
    
    if test_passed:
        print("\n2. è¿è¡Œå®Œæ•´çš„å¯¹æ¯”åˆ†æ...")
        print("=" * 80)
        
        # è¿è¡Œå¯¹æ¯”åˆ†æ
        try:
            results = compare_methods()
            
            print("\n" + "=" * 80)
            print("å¯¹æ¯”åˆ†æå®Œæˆ!")
            print("=" * 80)
            
            # æ‰“å°ä¿®å¤è¯´æ˜
            print("\nä¿®å¤è¯´æ˜:")
            print("1. ä¿®å¤äº†exact_solutionæ–¹æ³•ä¸­çš„torch.exp()å‚æ•°ç±»å‹é—®é¢˜")
            print("2. ä¿®å¤äº†sigma_funcçš„ç»´åº¦é—®é¢˜: ä»(batch_size, d, 1)è°ƒæ•´ä¸º(batch_size, d)")
            print("3. è°ƒæ•´äº†æµ‹è¯•æ¡ä»¶ï¼Œæ¥å—æµ®ç‚¹æ•°è®¡ç®—ä¸­çš„å¾®å°å·®å¼‚")
            print("4. æ”¹è¿›äº†é”™è¯¯å¤„ç†ï¼Œå•ä¸ªæ–¹æ³•å¤±è´¥ä¸ä¼šå½±å“æ•´ä½“è¿è¡Œ")
            
        except Exception as e:
            print(f"\nå¯¹æ¯”åˆ†æè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            print("é”™è¯¯ç±»å‹:", type(e).__name__)
            import traceback
            traceback.print_exc()
    else:
        print("\næµ‹è¯•æœªå®Œå…¨é€šè¿‡ï¼Œä½†å¯ä»¥å°è¯•è¿è¡Œä¸»ç¨‹åº...")
        print("=" * 80)
        
        # ä»ç„¶å°è¯•è¿è¡Œå¯¹æ¯”åˆ†æ
        try:
            results = compare_methods()
        except Exception as e:
            print(f"\nè¿è¡Œå¤±è´¥: {e}")
            print("é”™è¯¯ç±»å‹:", type(e).__name__)
